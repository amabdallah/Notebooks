{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 2.3: What differences are there across datasets in volume and elevation curves of a reservoir? \n",
    "\n",
    "This notebook demonstrates basic WaMDaM use cases analysis using scientific Python libraries such as [pandas](https://pandas.pydata.org/) and [plotly](https://plot.ly/).  It reads WaMDaM SQLite data from a published HydroShare Generic Resource, runs SQL script, and them uses Python plotly to visualize the results\n",
    "\n",
    "This use case identifies five volume-elevation curves for Hyrum Reservoir, Utah from three datasets: USBOR, Utah Dams, and WEAP model datasets\n",
    "\n",
    "For more info: http://docs.wamdam.org/UseCases/use_case_2/#use-case-2.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from utilities import hydroshare\n",
    "#from hs_restclient import HydroShare\n",
    "\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/0c/1b8241395302fd66b34a0fe0774ed83632afd14aa5c995b262fb7b3ac540/plotly-2.7.0.tar.gz (25.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.0MB 16kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.6 in /opt/conda/envs/python2/lib/python2.7/site-packages (from plotly)\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/envs/python2/lib/python2.7/site-packages (from plotly)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python2/lib/python2.7/site-packages (from plotly)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python2/lib/python2.7/site-packages (from plotly)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python2/lib/python2.7/site-packages (from plotly)\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/envs/python2/lib/python2.7/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/envs/python2/lib/python2.7/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/envs/python2/lib/python2.7/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/envs/python2/lib/python2.7/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python2/lib/python2.7/site-packages (from requests->plotly)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/envs/python2/lib/python2.7/site-packages (from requests->plotly)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/envs/python2/lib/python2.7/site-packages (from requests->plotly)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python2/lib/python2.7/site-packages (from requests->plotly)\n",
      "Requirement already satisfied: enum34; python_version == \"2.7\" in /opt/conda/envs/python2/lib/python2.7/site-packages (from traitlets>=4.1->nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: functools32; python_version == \"2.7\" in /opt/conda/envs/python2/lib/python2.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly)\n",
      "Building wheels for collected packages: plotly\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/0c/3e/07/4848195c61f659184ca41d5a614845a018ab2d2f2a705b9998\n",
      "Successfully built plotly\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-2.7.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "/bin/sh: 1: pip3: not found\n",
      "Fetching package metadata ...................\n",
      "Solving package specifications: .\n",
      "\n",
      "Package plan for installation in environment /opt/conda:\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    plotly:       2.7.0-py_1                    conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    scikit-learn: 0.18.2-py36_blas_openblas_201 conda-forge [blas_openblas] --> 0.19.1-py36_nomklh27f7947_0 defaults [nomkl]\n",
      "    scipy:        0.19.1-py36_blas_openblas_202 conda-forge [blas_openblas] --> 1.1.0-py36_nomklh9d22d0a_0  defaults [nomkl]\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    blas:         1.1-openblas                  conda-forge --> 1.0-mkl                     defaults\n",
      "    numpy:        1.12.1-py36_blas_openblas_200 conda-forge [blas_openblas] --> 1.12.1-py36_nomkl_0         defaults [nomkl]\n",
      "\n",
      "blas-1.0-mkl.t 100% |################################| Time: 0:00:00   3.50 MB/s\n",
      "numpy-1.12.1-p 100% |################################| Time: 0:00:00  11.47 MB/s\n",
      "scipy-1.1.0-py 100% |################################| Time: 0:00:01  15.26 MB/s\n",
      "scikit-learn-0 100% |################################| Time: 0:00:00  10.62 MB/s\n",
      "plotly-2.7.0-p 100% |################################| Time: 0:00:01  18.39 MB/s\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly  # python 2.7\n",
    "!pip3 install plotly # python3\n",
    "!conda install -c plotly plotly -y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "WaMDaM database test file (SQLite) on HydroShare\n",
    "https://www.hydroshare.org/resource/1601e9f029984a87affcd94af6b4bad0/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "from utilities import hydroshare\n",
    "#from hs_restclient import HydroShare\n",
    "\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to establish a secure connection with HydroShare. This is done by simply instantiating the hydroshare class that is defined within hs_utils. In addition to connecting with HydroShare, this command also sets environment variables for several parameters that may useful to you:\n",
    "\n",
    "Your username\n",
    "The ID of the resource which launched the notebook\n",
    "The type of resource that launched this notebook\n",
    "The url for the notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a secure connection to HydroShare\n",
    "hs = hydroshare.hydroshare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve a resource using its ID\n",
    "\n",
    "# The data for our processing routines can be retrieved using the `getResourceFromHydroShare` function by passing it the global identifier from the url above\n",
    "# get some resource content. The resource content is returned as a dictionary\n",
    "# Abdallah, A. (2018). Bear River Datasets, HydroShare, http://www.hydroshare.org/resource/bec9b20118804d119c4bfc232caea559\n",
    "content = hs.getResourceFromHydroShare('bec9b20118804d119c4bfc232caea559')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SQLite engine to connect to the SQLite file. \n",
    "# Then we can run queries against it within this notebook :)  \n",
    "conn = sqlite3.connect(hs.content[\"BearRiverDatasets_Jan2018.sqlite\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query multiple volume/elevation curves into one table to plot them together\n",
    "\n",
    "# 4.2MultiAttributeValues.csv\n",
    "import urllib\n",
    "\n",
    "# for simplicity, we call the query directly from GitHub as a text. You may use the query here but it will be too long to show in a cell \n",
    "#https://github.com/WamdamProject/WaMDaM_UseCases/blob/master/UseCases_files/4Queries_SQL/UseCase2/UseCase2.3/4_MultiAttributeValues.sql\n",
    "\n",
    "txt1 = urllib.urlopen(\"https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase2/UseCase2.3/3_MultipleTimeSeriesColumnsSameTimeStamp.sql\").read()\n",
    "\n",
    "# pass the query to the SQLite connection\n",
    "df = pd.read_sql_query(txt1, conn)\n",
    "\n",
    "# Save the query result into a CSV file\n",
    "df.to_csv('query_resut.csv')\n",
    "\n",
    "# to print the table result here within the notebook, just uncomment the df line below\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two time series with the same time stamp and merge them to be ready to plot them as part of the Volume-Elevation curve\n",
    "\n",
    "# 4.3MergeTimeSeriesValues.sql\n",
    "import urllib\n",
    "txt2 = urllib.urlopen(\"https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase2/UseCase2.3/3_MergeTimeSeriesValues.sql\").read()\n",
    "\n",
    "# pass the query to the SQLite connection\n",
    "df2 = pd.read_sql_query(txt2, conn)\n",
    "\n",
    "# Save the query result into a CSV file\n",
    "df2.to_csv('query_resut2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly libraries and set it to the notebook mode to embed the figures within a cell\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UseCase2.3_HyrumReservoir_Curves.py\n",
    "\n",
    "# plot multi-attributes from multiple sources\n",
    "\n",
    "\n",
    "# Adel Abdallah\n",
    "# Jan 25, 2018\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "\n",
    "## read the input data from GitHub csv file which is a direct query output for these queries:\n",
    "\n",
    "# 4.2MultiAttributeValues.csv\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/5Results_CSV/4.2MultiAttributeValues.csv\")\n",
    "\n",
    "# 4.3MergeTimeSeriesValues.sql\n",
    "df2 = pd.read_csv(\"https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/5Results_CSV/4.3MergeTimeSeriesValues.csv\")\n",
    "\n",
    "\n",
    "subsets = df.groupby('ScenarioName')\n",
    "data = []\n",
    "\n",
    "#for each subset (curve), set up its legend and line info manually so they can be edited\n",
    "subsets_settings = {\n",
    "    'Utah Dams shapefile_as is': { # this oone is the name of subset as it appears in the csv file\n",
    "        'dash': 'solid',     # this is properity of the line (curve)\n",
    "        'width':'3',\n",
    "        'legend_index': 1,   # to order the legend\n",
    "         'symbol':'square',\n",
    "        'size':'7',\n",
    "        'mode':'line+markers',\n",
    "        'legend_name': 'Utah Dams Dataset (2016)',  # this is the manual curve name \n",
    "         'color':'#990F0F'\n",
    "        },\n",
    "    \n",
    "    'USU WEAP Model 2017': {\n",
    "        'dash': 'solid',\n",
    "         'width':'3',\n",
    "          'mode':'line+markers',\n",
    "          'symbol':'circle',\n",
    "                'size':'7',\n",
    "\n",
    "        'legend_index': 3,\n",
    "        'legend_name': 'USU WEAP Model (2017)',\n",
    "         'color':'#B26F2C'\n",
    "        },\n",
    "    'UDWR GenRes 2010': {\n",
    "        'dash': 'dash',\n",
    "        'mode':'line+markers',\n",
    "        'width':'3',\n",
    "                'size':'7',\n",
    "\n",
    "        'symbol':'circle',\n",
    "        'legend_index': 4,\n",
    "        'legend_name': 'UDWR WEAP Model (2010)',\n",
    "         'color':'#7A430C'\n",
    "        },\n",
    "    'Rwise': {\n",
    "        'dash': 'dash',\n",
    "        'mode':'line+markers',\n",
    "        'width':'3',\n",
    "                  'symbol':'star',\n",
    "                'size':'7',\n",
    "\n",
    "        'legend_index': 0,\n",
    "        'legend_name': 'BOR Water Info. System (2017)',\n",
    "         'color':'#E57E7E'\n",
    "        },\n",
    "    'Base case': {\n",
    "        'dash': 'solid',\n",
    "        'mode':'lines+markers',\n",
    "        'width':'3',\n",
    "                  'symbol':'bowtie',\n",
    "        'size':'11',\n",
    "\n",
    "        'legend_index': 2,\n",
    "        'legend_name': 'BOR Reservoirs Dataset (2006)',\n",
    "         'color':'#E5B17E'\n",
    "        },    \n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "# This dict is used to map legend_name to original subset name\n",
    "subsets_names = {y['legend_name']: x for x,y in subsets_settings.iteritems()}\n",
    "\n",
    "      \n",
    "#for each subset (curve), set up its legend and line info manually so they can be edited\n",
    "subsets_settings2 = {\n",
    "        'dash': 'solid',     # this is properity of the line (curve)\n",
    "        'legend_index': 3,   # to order the legend\n",
    "         'mode':'lines+markers',\n",
    "        'color':'#E57E7E',\n",
    "        'legend_name': 'BOR Water Info. System (2017)'  # this is the edited curve name \n",
    "                    }\n",
    "\n",
    "\n",
    "# Get data from first dataframe (Multi-Attributes)\n",
    "for subset in subsets.groups.keys():\n",
    "    print subset\n",
    "    scenario_name_data = subsets.get_group(name=subset)\n",
    "    subsets_of_scenario = scenario_name_data.groupby(\"AttributeNameCV\")\n",
    "    s = go.Scatter(\n",
    "                    x=subsets_of_scenario.get_group(name='Volume').Value,\n",
    "                    y=subsets_of_scenario.get_group(name='Elevation').Value,\n",
    "                        mode='lines+markers',\n",
    "\n",
    "                    name = subsets_settings[subset]['legend_name'],\n",
    "                    line = dict(\n",
    "                        color =subsets_settings[subset]['color'],\n",
    "                        width =subsets_settings[subset]['width'],\n",
    "                        dash=subsets_settings[subset]['dash']\n",
    "                                ),\n",
    "                     marker = dict(\n",
    "                         size=subsets_settings[subset]['size'],\n",
    "                         symbol=subsets_settings[subset]['symbol'],\n",
    "                         #color = '#a50021',\n",
    "                         maxdisplayed=12\n",
    "),  \n",
    "                    opacity = 1)\n",
    "    data.append(s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get data from second dataframe (merged two time series as two Multi-Attributes)\n",
    "data2 = go.Scatter(\n",
    "                x=df2.VolumeValue,\n",
    "                y=df2['ElevationValue'],\n",
    "                name = subsets_settings2['legend_name'],\n",
    "                mode='lines+markers',\n",
    "                line = dict(\n",
    "                    color ='#E57E7E',\n",
    "                    width ='3'),\n",
    "                marker = dict(\n",
    "                size ='9',\n",
    "                color = '#E57E7E',\n",
    "                maxdisplayed=20,\n",
    "                symbol ='star',\n",
    "                         line = dict(\n",
    "                         color = ['rgb(153, 84, 15)']\n",
    "                         ),\n",
    "\n",
    "                            ),\n",
    "    \n",
    "    \n",
    "                opacity =1)\n",
    "                \n",
    "data.append(data2)     \n",
    "    \n",
    "# Legend is ordered based on data, so we are sorting the data based \n",
    "# on desired legend order indicarted by the index value entered above\n",
    "data.sort(key=lambda x: subsets_settings[subsets_names[x['name']]]['legend_index'])\n",
    "\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=[1500, 8000, 16000],\n",
    "    y=[4680, 4680,4680],\n",
    "    mode='text',\n",
    "    showlegend=False,\n",
    "    text=['Dead<br> storage', 'Live<br>storage', 'Total<br>storage'],\n",
    "    textposition='top',\n",
    "\n",
    ")\n",
    "data.append(trace1)     \n",
    "\n",
    "\n",
    "# set up the figure layout\n",
    "layout = {\n",
    "        'shapes': [\n",
    "        # Rectangle reference to the axes\n",
    "        {\n",
    "            \"opacity\": 0.3,\n",
    "            'type': 'rect',\n",
    "            'xref': 'x',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': 4580,\n",
    "            'x1': 3012,\n",
    "            'y1': 4750,\n",
    "            'line': {\n",
    "                'color': 'rgb(0, 0, 0)',\n",
    "                'width': 0.1,\n",
    "            },\n",
    "            'fillcolor': 'rgb(153, 229, 255)'\n",
    "        },\n",
    "     # Rectangle reference to the plot\n",
    "        {\n",
    "           \"opacity\": 0.3,\n",
    "            'type': 'rect',\n",
    "            'xref': 'x',\n",
    "            'yref': 'y',\n",
    "            'x0': 3012,\n",
    "            'y0': 4580,\n",
    "            'x1': 14440,\n",
    "            'y1': 4750,\n",
    "            'line': {\n",
    "                'color': 'rgb(0, 0, 0)',\n",
    "                'width': 0.1,\n",
    "            },\n",
    "            'fillcolor': 'rgb(127, 212, 255)',\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"opacity\": 0.3,\n",
    "            'type': 'rect',\n",
    "            'xref': 'x',\n",
    "            'yref': 'y',\n",
    "            'x0': 14440,\n",
    "            'y0': 4580,\n",
    "            'x1': 17746,\n",
    "            'y1': 4750,\n",
    "            'line': {\n",
    "                'color': 'rgb(0, 0, 0)',\n",
    "                'width': 0.1,\n",
    "            },\n",
    "            'fillcolor': 'rgb(101, 191, 255)',\n",
    "        }        \n",
    "    ],\n",
    "        'yaxis': {\n",
    "        'title': 'Elevation (feet)',\n",
    "        'tickformat': ',',\n",
    "        'ticks':'outside',\n",
    "        'ticklen': '10',\n",
    "\n",
    "\n",
    "        'range' : ['4580', '4700'],\n",
    "                'showline':'True'\n",
    "\n",
    "                },\n",
    "    'xaxis' : {\n",
    "        'title' : 'Volume (acre-feet)',\n",
    "        'tickformat': ',',   \n",
    "         'showgrid':False,\n",
    "\n",
    "        'ticks':'outside',\n",
    "        'dtick':'5000',\n",
    "        'range' : ['0', '30000'],\n",
    "        'ticklen':20,\n",
    "        'tick0':0,\n",
    "        'showline':True,\n",
    "    },\n",
    "    'legend':{\n",
    "        'x':0.45,\n",
    "        'y':0.04,\n",
    "        'bordercolor':'#00000',\n",
    "         'borderwidth':2    \n",
    "    },\n",
    "    'width':1200,\n",
    "    'height':800,\n",
    "    'margin':go.Margin(\n",
    "        l=150,\n",
    "        b=150       ),\n",
    "    #paper_bgcolor='rgb(233,233,233)',\n",
    "    #plot_bgcolor='rgb(233,233,233)',\n",
    "    'font':{'size':32,'family':'arial'},\n",
    "    \n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "    #title = \"UseCase5\",\n",
    "    \n",
    "\n",
    "\n",
    "fig = {\n",
    "    'data': data,\n",
    "    'layout': layout,}\n",
    "\n",
    "\n",
    "#py.iplot(fig, filename = \"4_HyrumReservoir_Curves.py\") \n",
    "\n",
    "\n",
    "## it can be run from the local machine on Pycharm like this like below\n",
    "## It would also work here offline but in a seperate window  \n",
    "#plotly.offline.plot(fig, filename = \"4_HyrumReservoir_Curves.py\") offline.iplot(fig,filename = 'jupyter/2.2Identify_aggregate_TimeSeriesValues' )       \n",
    "\n",
    "# offline.iplot(fig,filename = 'jupyter/4_HyrumReservoir_Curves')       \n",
    "\n",
    "offline.iplot(fig,filename = 'jupyter/4_HyrumReservoir_Curves',\n",
    "             image='png')\n",
    "# it might take 30-60 seconds to load the html interactive image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='section4'></a>\n",
    "### 4. Creating a new HydroShare resource\n",
    "\n",
    "The best way to save your data is to put it back into HydroShare and is done using the `createHydroShareResource` function. The first step is to identify the files you want to save to a HydroShare.  The cell below lists all the files in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My files: ['2.4_plotcdf.html', 'CDF_data.csv', 'Filtered Data.csv', 'query_resut2.csv', 'query_resut.csv', 'UseCase2.2_dentifyDemandSites_TimeSeriesValues.html', 'WaMDaM_UseCase1.ipynb', 'WaMDaM_Use_Case2.1.ipynb', 'WaMDaM_Use_Case2.2.ipynb', 'WaMDaM_Use_Case2.3.ipynb', 'WaMDaM_Use_Case2.4.ipynb', 'WaMDaM_UseCase3.ipynb', 'WaMDaM_Use_Cases_Overview.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# Grab all the files in the folder where you are working  \n",
    "files = !ls\n",
    "print('My files: %s' % files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save this content as a new resource in HydroShare\n",
    "abstract = 'This is a demo of the HydroShare Python Notebook Server for WaMDaM'\n",
    "title = 'WaMDaM_Use_Case2.3'    \n",
    "keywords = ['Demo', 'JupyterHub']  \n",
    "rtype = 'genericresource'          \n",
    "\n",
    "# create a list of files that will be added to the HydroShare resource.\n",
    "#files = ['WaMDaM_use_cases_Multi_columns.ipynb.ipynb']  # this notebook\n",
    "        \n",
    "# create a list of files that will be added to the HydroShare resource.\n",
    "    \n",
    "files = [hs.content['BearRiverDatasets_Jan2018.sqlite'],'WaMDaM_Use_Case2.3.ipynb']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HydroShare Resource -"
     ]
    }
   ],
   "source": [
    "    \n",
    "# create the new resource\n",
    "resource_id = hs.createHydroShareResource(abstract, \n",
    "                                          title, \n",
    "                                          keywords=keywords, \n",
    "                                          resource_type=rtype, \n",
    "                                          content_files=files, \n",
    "                                          public=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
