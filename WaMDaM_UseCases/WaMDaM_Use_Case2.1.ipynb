{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WaMDaM_Use_Case2.1: What differences are there across datasets in flow data values at a site? \n",
    "\n",
    "This notebook demonstrates basic WaMDaM use cases analysis using scientific Python libraries such as [pandas](https://pandas.pydata.org/) and [plotly](https://plot.ly/).  It reads WaMDaM SQLite data from a published HydroShare Generic Resource, runs SQL script, and them uses Python plotly to visualize the results\n",
    "\n",
    "**What differences are there across datasets in volume and elevation curves of Hyrum Reservoir, Utah?**\n",
    "\n",
    "This use case identifies five time series and seasonal flow data for the site below Stewart Dam, Idaho\n",
    "\n",
    "For more info: http://docs.wamdam.org/UseCases/use_case_2/#use-case-2.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a resource using its ID\n",
    "\n",
    "WaMDaM database test file (SQLite) on HydroShare\n",
    "https://www.hydroshare.org/resource/1601e9f029984a87affcd94af6b4bad0/\n",
    "\n",
    "The data for our processing routines can be retrieved using the `getResourceFromHydroShare` function by passing it the global identifier from the url above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utilities import hydroshare\n",
    "#from hs_restclient import HydroShare\n",
    "\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from random import randint\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly  # python 2.7\n",
    "!pip3 install plotly # python3\n",
    "!conda install -c plotly plotly -y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to establish a secure connection with HydroShare. This is done by simply instantiating the hydroshare class that is defined within hs_utils. In addition to connecting with HydroShare, this command also sets environment variables for several parameters that may useful to you:\n",
    "\n",
    "Your username\n",
    "The ID of the resource which launched the notebook\n",
    "The type of resource that launched this notebook\n",
    "The url for the notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a secure connection to HydroShare\n",
    "hs = hydroshare.hydroshare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve a resource using its ID\n",
    "\n",
    "# The data for our processing routines can be retrieved using the `getResourceFromHydroShare` function by passing it the global identifier from the url above\n",
    "# get some resource content. The resource content is returned as a dictionary\n",
    "# Abdallah, A. (2018). Bear River Datasets, HydroShare, http://www.hydroshare.org/resource/bec9b20118804d119c4bfc232caea559\n",
    "content = hs.getResourceFromHydroShare('bec9b20118804d119c4bfc232caea559')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(hs.content[\"BearRiverDatasets_Jan2018.sqlite\"])\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "# \n",
    "txt = urllib.urlopen(\"https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase2/UseCase2.1/2_Identify_aggregate_TimeSeriesValues.sql\").read()\n",
    "\n",
    "#df_TimeSeries = pd.read_sql_query(txt, conn)\n",
    "#df_TimeSeries.to_csv('query_resut.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 2.2Identify_aggregate_TimeSeriesValues.csv\n",
    "# plot aggregated to monthly and converted to acre-feet time series data of multiple sources\n",
    "\n",
    "# Adel Abdallah\n",
    "# November 16, 2017\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "\n",
    "## read the input data from GitHub csv file which is a direct query output for this  query:\n",
    "# 2.2Identify_aggregate_TimeSeriesValues.csv\n",
    "\n",
    "df_TimeSeries = pd.read_csv(\"https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/5Results_CSV/2.2Identify_aggregate_TimeSeriesValues.csv\")\n",
    "\n",
    "#df = pd.read_csv(results)\n",
    "\n",
    "# identify the data for four time series only based on the DatasetAcronym column header \n",
    "column_name = \"DatasetAcronym\"\n",
    "subsets = df_TimeSeries.groupby(column_name)\n",
    "data = []\n",
    "\n",
    "# for each subset (curve), set up its legend and line info manually so they can be edited\n",
    "subsets_settings = {\n",
    "    'UDWRFlowData': {\n",
    "        'dash': 'solid',\n",
    "        'legend_index': 0,\n",
    "        'legend_name': 'Utah Division of Water Res.',\n",
    "        'width':'3',\n",
    "        'color':'rgb(153, 15, 15)'\n",
    "        },\n",
    "    'CUHASI': {\n",
    "        'dash': 'dash',\n",
    "        'legend_index': 1,\n",
    "        'legend_name': 'USGS',\n",
    "        'width':'4',\n",
    "        'color':'rgb(15, 107, 153)'\n",
    "        },\n",
    "    'IdahoWRA': {\n",
    "        'dash': 'soild',\n",
    "        'legend_index': 2,\n",
    "        'legend_name': 'Idaho Department of Water Res.',\n",
    "        'width':'3',\n",
    "        'color':'rgb(38, 15, 153)'\n",
    "        },    \n",
    "    'BearRiverCommission': { # this oone is the name of subset as it appears in the csv file\n",
    "        'dash': 'dot',     # this is properity of the line (curve)\n",
    "        'legend_index': 3,   # to order the legend\n",
    "        'legend_name': 'Bear River Commission',  # this is the manual curve name \n",
    "         'width':'4',\n",
    "        'color':'rgb(107, 153, 15)'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "# This dict is used to map legend_name to original subset name\n",
    "subsets_names = {y['legend_name']: x for x,y in subsets_settings.iteritems()}\n",
    "\n",
    "# prepare the scater plot for each curve\n",
    "for subset in subsets.groups.keys():\n",
    "    #print subset\n",
    "    dt = subsets.get_group(name=subset)\n",
    "    s = go.Scatter(\n",
    "                    x=dt.CalenderYear.map(lambda z: str(z)[:-3]),\n",
    "                    y=dt['CumulativeMonthly'],\n",
    "                    name = subsets_settings[subset]['legend_name'],\n",
    "                    line = dict(\n",
    "                        color =subsets_settings[subset]['color'],\n",
    "                        width =subsets_settings[subset]['width'], \n",
    "                        dash=subsets_settings[subset]['dash']\n",
    "                               ),\n",
    "                        opacity = 1                                \n",
    "                  )\n",
    "    data.append(s)\n",
    "    \n",
    "# Legend is ordered based on data, so we are sorting the data based \n",
    "# on desired legend order indicarted by the index value entered above\n",
    "data.sort(key=lambda x: subsets_settings[subsets_names[x['name']]]['legend_index'])\n",
    "\n",
    "# set up the figure layout parameters\n",
    "layout = dict(\n",
    "     #title = \"UseCase3.2\",\n",
    "     yaxis = dict(\n",
    "         title = \"Cumulative monthly flow <br> (acre-feet/month)\",\n",
    "         tickformat= ',',\n",
    "         zeroline=True,\n",
    "         showline=True,\n",
    "         ticks='outside',\n",
    "         ticklen=15,\n",
    "         #zerolinewidth=4,\n",
    "         zerolinecolor='#00000',\n",
    "\n",
    "         dtick=30000,\n",
    "                 ),\n",
    "    xaxis = dict(\n",
    "         #title = \"Time <br> (month/year)\",\n",
    "         #autotick=False,\n",
    "        tick0='1900-01-01',\n",
    "        dtick='M180',\n",
    "        ticks='inside',\n",
    "        tickwidth=0.5,\n",
    "        #zerolinewidth=4,\n",
    "        ticklen=27,\n",
    "        zerolinecolor='#00000',\n",
    "        tickcolor='#000',\n",
    "        tickformat= \"%Y\",\n",
    "       range = ['1920', '2020']\n",
    "\n",
    "                ),\n",
    "    legend=dict(\n",
    "        x=0.2,y=0.9,\n",
    "        bordercolor='#00000',\n",
    "            borderwidth=2\n",
    "\n",
    "\n",
    "                ),\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=go.Margin(l=300, b=150),\n",
    "    #paper_bgcolor='rgb(233,233,233)',\n",
    "    #plot_bgcolor='rgb(233,233,233)',\n",
    "    \n",
    "    \n",
    "    font=dict( size=35)\n",
    "             )\n",
    "# create the figure object            \n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "# plot the figure \n",
    "offline.iplot(fig,filename = 'jupyter/2.2Identify_aggregate_TimeSeriesValues' )       \n",
    "\n",
    "\n",
    "## it can be run from the local machine on Pycharm like this like below\n",
    "## It would also work here offline but in a seperate window  \n",
    "\n",
    "#plotly.offline.plot(fig, filename = \"2.2Identify_aggregate_TimeSeriesValues.html\") \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zone in to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 2.2bIdentify_aggregate_TimeSeriesValues.py\n",
    "# plot aggregated to monthly and converted to acre-feet time series data of multiple sources\n",
    "\n",
    "# Adel Abdallah\n",
    "# November 16, 2017\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "\n",
    "## read the input data from GitHub csv file which is a direct query output for this  query:\n",
    "# 3.2Identify_aggregate_TimeSeriesValues.sql\n",
    "\n",
    "\n",
    "# identify the data for four time series only based on the DatasetAcronym column header \n",
    "column_name = \"DatasetAcronym\"\n",
    "subsets = df_TimeSeries.groupby(column_name)\n",
    "data = []\n",
    "\n",
    "# for each subset (curve), set up its legend and line info manually so they can be edited\n",
    "\n",
    "subsets_settings = {\n",
    "    'UDWRFlowData': {\n",
    "        'symbol': \"star\",\n",
    "        'legend_index': 0,\n",
    "        'legend_name': 'Utah Division of Water Res.',\n",
    "        'width':'2',\n",
    "        'size' :'7',\n",
    "        'color':'rgb(153, 15, 15)',\n",
    "        'mode': 'lines+markers'\n",
    "        },\n",
    "    'CUHASI': {\n",
    "        'symbol': \"square\",\n",
    "        'legend_index': 1,\n",
    "         'size' :'10',\n",
    "        'legend_name': 'CUAHSI',\n",
    "        'width':'3',\n",
    "        'color':'rgb(15, 107, 153)',\n",
    "        'show_legend': False,\n",
    "        },\n",
    "    'IdahoWRA': {\n",
    "        'symbol': \"triangle-down\",\n",
    "        'legend_index': 2,\n",
    "         'size' :'6',\n",
    "        'legend_name': 'Idaho Department of Water Res.',\n",
    "        'width':'3',\n",
    "        'color':'rgb(38, 15, 153)'\n",
    "        },    \n",
    "    'BearRiverCommission': { # this one is the name of subset as it appears in the csv file\n",
    "        'symbol': \"106\",     # this is property of the line (curve)\n",
    "                'size' :'6',\n",
    "\n",
    "        'legend_index': 3,   # to order the legend\n",
    "        'legend_name': \"Bear River Commission\",  # this is the manual curve name \n",
    "         'width':'4',\n",
    "        'color':'rgb(107, 153, 15)'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "# This dict is used to map legend_name to original subset name\n",
    "subsets_names = {y['legend_name']: x for x,y in subsets_settings.iteritems()}\n",
    "\n",
    "# prepare the scater plot for each curve\n",
    "for subset in subsets.groups.keys():\n",
    "    print subset\n",
    "    dt = subsets.get_group(name=subset)\n",
    "    s = go.Scatter(\n",
    "        x=dt.CalenderYear.map(lambda z: str(z)[:-3]),\n",
    "        y=dt['CumulativeMonthly'],\n",
    "        name = subsets_settings[subset]['legend_name'],       \n",
    "        opacity = 1,\n",
    "        \n",
    "        # Get mode from settings dictionary, if there is no mode\n",
    "        # defined in dictinoary, then default is markers.\n",
    "        mode = subsets_settings[subset].get('mode', 'markers'),\n",
    "        \n",
    "        # Get legend mode from settings dictionary, if there is no mode\n",
    "        # defined in dictinoary, then default is to show item in legend.\n",
    "        showlegend = subsets_settings[subset].get('show_legend', True),\n",
    "        \n",
    "        marker = dict(\n",
    "            size =subsets_settings[subset]['size'],\n",
    "            color = '#FFFFFF',      # white\n",
    "            symbol =subsets_settings[subset]['symbol'],\n",
    "            line = dict(\n",
    "                color =subsets_settings[subset]['color'],\n",
    "                width =subsets_settings[subset]['width'], \n",
    "                ),\n",
    "            ),\n",
    "            \n",
    "        line = dict(\n",
    "            color =subsets_settings[subset]['color'],\n",
    "            width =subsets_settings[subset]['width'], \n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    data.append(s)\n",
    "    \n",
    "# Legend is ordered based on data, so we are sorting the data based \n",
    "# on desired legend order indicated by the index value entered above\n",
    "data.sort(key=lambda x: subsets_settings[subsets_names[x['name']]]['legend_index'])\n",
    "\n",
    "# set up the figure layout parameters\n",
    "layout = dict(\n",
    "     #title = \"UseCase3.2\",\n",
    "     yaxis = dict(\n",
    "         title = \"Cumulative monthly flow <br> (acre-feet/month)\",\n",
    "         tickformat= ',',\n",
    "         zeroline=True,\n",
    "         showline=True,\n",
    "         ticks='outside',\n",
    "         ticklen=15,\n",
    "         #zerolinewidth=4,\n",
    "         zerolinecolor='#00000',\n",
    "         range = ['0', '6000'],\n",
    "         dtick=1000,\n",
    "                 ),\n",
    "    xaxis = dict(\n",
    "         #title = \"Time <br> (month/year)\",\n",
    "         #autotick=False,\n",
    "        tick0='1994-01-01',\n",
    "        showline=True,\n",
    "        dtick='M12',\n",
    "        ticks='outside',\n",
    "        tickwidth=0.5,\n",
    "        #zerolinewidth=4,\n",
    "        ticklen=27,\n",
    "        #zerolinecolor='#00000',\n",
    "        tickcolor='#000',\n",
    "        tickformat= \"%Y\",\n",
    "        range = ['1994', '2000']\n",
    "                ),\n",
    "    legend=dict(\n",
    "        x=0.3,y=1,\n",
    "        bordercolor='#00000',\n",
    "            borderwidth=2\n",
    "\n",
    "\n",
    "                ),\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=go.Margin(l=300, b=150),\n",
    "    #paper_bgcolor='rgb(233,233,233)',\n",
    "    #plot_bgcolor='rgb(233,233,233)',\n",
    "    \n",
    "    \n",
    "    font=dict( size=35)\n",
    "             )\n",
    "             \n",
    "# create the figure object            \n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "# plot the figure \n",
    "#py.iplot(fig, filename = \"2.2bIdentify_aggregate_TimeSeriesValues\")       \n",
    "\n",
    "\n",
    "## it can be run from the local machine on Pycharm like this like below\n",
    "## It would also work here offline but in a seperate window  \n",
    "offline.iplot(fig,filename = 'jupyter/2.2bIdentify_aggregate_TimeSeriesValues' )       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal flow data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "# \n",
    "txt = urllib.urlopen(\"https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase2/UseCase2.1/3_Identify_SeasonalValues.sql\").read()\n",
    "\n",
    "#df_Seasonal = pd.read_sql_query(txt, conn)\n",
    "#df_Seasonal.to_csv('query_resut.csv')\n",
    "#df_Seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 2.3Identify_SeasonalValues\n",
    "\n",
    "# plot Seasonal data for multiple scenarios\n",
    "\n",
    "# Adel Abdallah\n",
    "# November 16, 2017\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "\n",
    "## read the input data from GitHub csv file which is a direct query output\n",
    "# 3.3Identify_SeasonalValues.csv \n",
    "\n",
    "df_Seasonal = pd.read_csv(\"https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/5Results_CSV/2.3Identify_SeasonalValues.csv\")\n",
    "\n",
    "#get the many curves by looking under \"ScenarioName\" column header. \n",
    "#Then plot Season name vs season value\n",
    "column_name = \"ScenarioName\"\n",
    "subsets = df_Seasonal.groupby(column_name)\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "#for each subset (curve), set up its legend and line info manually so they can be edited\n",
    "subsets_settings = {\n",
    "    'Bear Wet Year Model': {\n",
    "        'dash': 'solid',\n",
    "         'mode':'lines+markers',\n",
    "        'width':'4',\n",
    "        'legend_index': 0,\n",
    "        'legend_name': 'Wet Year Model',\n",
    "         'color':'rgb(41, 10, 216)'\n",
    "        },\n",
    "\n",
    "    'Bear Normal Year Model': { # this oone is the name of subset as it appears in the csv file\n",
    "        'dash': 'solid',     # this is properity of the line (curve)\n",
    "        'width':'4',\n",
    "        'mode':'lines+markers',\n",
    "        'legend_index': 1,   # to order the legend\n",
    "        'legend_name': 'Normal Year Model',  # this is the manual curve name \n",
    "         'color':'rgb(38, 77, 255)'\n",
    "\n",
    "        },\n",
    "    'Bear Dry Year Model': {\n",
    "        'dash': 'solid',\n",
    "        'mode':'lines+markers',\n",
    "         'width':'4',\n",
    "        'legend_index': 2,\n",
    "        'legend_name': 'Dry Year Model',\n",
    "         'color':'rgb(63, 160, 255)'\n",
    "        },\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "# This dict is used to map legend_name to original subset name\n",
    "subsets_names = {y['legend_name']: x for x,y in subsets_settings.iteritems()}\n",
    "\n",
    "\n",
    "for subset in subsets.groups.keys():\n",
    "    print subset\n",
    "    dt = subsets.get_group(name=subset)\n",
    "    s = go.Scatter(\n",
    "                    x=df_Seasonal.SeasonName,\n",
    "                    y=dt['SeasonNumericValue'],\n",
    "                    name = subsets_settings[subset]['legend_name'],\n",
    "                    line = dict(\n",
    "                        color =subsets_settings[subset]['color'],\n",
    "                        width =subsets_settings[subset]['width'],\n",
    "                        dash=subsets_settings[subset]['dash']\n",
    "                                ),\n",
    "                    marker=dict(size=10),            \n",
    "                    opacity = 0.8\n",
    "                   )\n",
    "    data.append(s)\n",
    "    \n",
    "    \n",
    "# Legend is ordered based on data, so we are sorting the data based \n",
    "# on desired legend order indicarted by the index value entered above\n",
    "data.sort(key=lambda x: subsets_settings[subsets_names[x['name']]]['legend_index'])\n",
    "\n",
    "    \n",
    "\n",
    "layout = dict(\n",
    "    #title = \"Use Case 3.3\",\n",
    "    yaxis = dict(\n",
    "        title = \"Cumulative flow <br> (acre-feet/month)\",\n",
    "        tickformat= ',',\n",
    "        showline=True,\n",
    "        dtick='5000',\n",
    "        ticks='outside',\n",
    "        ticklen=10\n",
    "\n",
    "                ),\n",
    "    \n",
    "    xaxis = dict(\n",
    "        #title = \"Month\",\n",
    "        ticks='inside',\n",
    "\n",
    "        ticklen=25\n",
    "                    ),\n",
    "    legend=dict(\n",
    "        x=0.6,y=0.5,\n",
    "          bordercolor='#00000',\n",
    "            borderwidth=2\n",
    "               ),\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    #paper_bgcolor='rgb(233,233,233)',\n",
    "    #plot_bgcolor='rgb(233,233,233)',\n",
    "    margin=go.Margin(l=260,b=100),\n",
    "    font=dict(size=35)\n",
    "             )\n",
    "# create a figure object\n",
    "fig = dict(data=data, layout=layout)\n",
    "#py.iplot(fig, filename = \"2.3Identify_SeasonalValues\") \n",
    "\n",
    "\n",
    "## it can be run from the local machine on Pycharm like this like below\n",
    "## It would also work here offline but in a seperate window  \n",
    "offline.iplot(fig,filename = 'jupyter/3Identify_SeasonalValues' )       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDF Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 2.4_plotcdf \n",
    "\n",
    "# plot Cumulative flow for June for the UDWR dataset. \n",
    "# Then get the percentage of time it exceeds dry and wet years \n",
    "\n",
    "# Adel Abdallah\n",
    "# Dec 2, 2017\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "## read the input data from GitHub csv file which is a direct query output for this  query:\n",
    "# 3.2Identify_aggregate_TimeSeriesValues.sql\n",
    "\n",
    "# Convert CalenderYear column data type to datetime\n",
    "df_TimeSeries['CalenderYear'] = pd.to_datetime(df_TimeSeries['CalenderYear'], errors='coerce')\n",
    "\n",
    "# Slice rows based on DatasetAcronym column\n",
    "subsets = df_TimeSeries.groupby('DatasetAcronym')\n",
    "\n",
    "# Select rows where DatasetAcronym is UDWRFlowData\n",
    "dt = subsets.get_group(name='UDWRFlowData')\n",
    "\n",
    "# From the selected rows, select rows where month is June\n",
    "specific_month = dt.CalenderYear.dt.month == 6\n",
    "\n",
    "# CumulativeMonthly data of the desired DatasetAcronym name and month\n",
    "cumulative_monthly = dt[specific_month].CumulativeMonthly.values.tolist()\n",
    "\n",
    "# Sort cumulative_monthly in ascending order\n",
    "cumulative_monthly.sort()\n",
    "\n",
    "# Save the filtered data to csv, CumulativeMonthly and CalenderYear columns\n",
    "filtered_data = dt[specific_month][['CumulativeMonthly', 'CalenderYear']]\n",
    "filtered_data.to_csv('Filtered Data.csv', index=False)\n",
    "\n",
    "\n",
    "# Create the y-axis list, which should be same length as x-axis and range\n",
    "# from 0 to 1, to represent probability and have equal spacing between it's\n",
    "# numbers, so we create a list of floats starting from 1 to length of\n",
    "# cumsum(which represents the x-axis) + 1, (+1) because we started from 1 not 0,\n",
    "# we want the same length of cumsum, and we are dividing the list by length of\n",
    "# cumsum to produce the desired probability values, So the last number in the\n",
    "# list should be equal to the length of cumsum, so that when we divide both\n",
    "# both values we get 1.\n",
    "# To get the last number equal length of cumsum, we have to use\n",
    "# max range = len(cumsum)+1, because np.arange will stop before\n",
    "# the maximum number, so it will stop at len(cumsum)\n",
    "probability = np.arange(1.0, len(cumulative_monthly)+1) /len(cumulative_monthly) # 1.0 to make it float\n",
    "\n",
    "data = []\n",
    "# just plot the sorted_data array against the number of items smaller \n",
    "# than each element in the array \n",
    "\n",
    "cdf = go.Scatter(\n",
    "    x = cumulative_monthly,\n",
    "    y = probability,\n",
    "        showlegend=True,\n",
    "name='UDWR from 1923 to 2014',\n",
    "    marker = dict(\n",
    "        color='rgb(0, 0, 0)'\n",
    "        )\n",
    "    )\n",
    "\n",
    "cdfdata=pd.DataFrame(data=dict(probability=probability,cumulative_monthly=cumulative_monthly))\n",
    "\n",
    "data.append(cdf)\n",
    "\n",
    "\n",
    "# Save the filtered data to csv, CumulativeMonthly and probability columns\n",
    "filtered_data = cdfdata\n",
    "filtered_data.to_csv('CDF_data.csv', index=False)\n",
    "\n",
    "\n",
    "# cdfdata\n",
    "\n",
    "lowerthanDry=cdfdata.loc[cdfdata['cumulative_monthly'] <= 666, 'probability']\n",
    "# print lowerthanDry\n",
    "\n",
    "UpperthanNormal=cdfdata.loc[cdfdata['cumulative_monthly'] >= 2506, 'probability']\n",
    "# print UpperthanNormal\n",
    "\n",
    "UpperthanWet=cdfdata.loc[cdfdata['cumulative_monthly'] >= 17181, 'probability']\n",
    "# print UpperthanWet\n",
    "\n",
    "\n",
    "\n",
    "# vertical line dry year \n",
    "dry = go.Scatter(\n",
    "    x=[666, 666 ],\n",
    "    y=[0, 0.48],\n",
    "    mode='lines',\n",
    "        name='Dry year scenario <br> (BRSDM model)',\n",
    "    hoverinfo='dry',\n",
    "    showlegend=True,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        width='4',\n",
    "        dash = 'dot',\n",
    "        color = '#3FA0FF'\n",
    "            )\n",
    "                    )\n",
    "data.append(dry)\n",
    "\n",
    "\n",
    "\n",
    "# horizontal line dry year \n",
    "dryHo = go.Scatter(\n",
    "    x=[0, 666 ],\n",
    "    y=[0.48, 0.48],\n",
    "    mode='lines',\n",
    "        name='Dry year scenario <br> (BRSDM model)',\n",
    "    hoverinfo='dry',\n",
    "    showlegend=False,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        width='4',\n",
    "        dash = 'dot',\n",
    "        color = '#3FA0FF'\n",
    "            )\n",
    "                    )\n",
    "data.append(dryHo)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# vertical line normal year \n",
    "normal = go.Scatter(\n",
    "    x=[2506, 2506],\n",
    "    y=[0, 0.844],\n",
    "    mode='lines',\n",
    "        name='Normal year scenario <br> (BRSDM model)',\n",
    "    hoverinfo='wet',\n",
    "    showlegend=True,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        dash = 'dashdot',\n",
    "        width='4',\n",
    "        color = '#264DFF'\n",
    "            )\n",
    "                    )\n",
    "data.append(normal)\n",
    "\n",
    "\n",
    "# horizontal line normal year \n",
    "normalHo = go.Scatter(\n",
    "    x=[0, 2506],\n",
    "    y=[0.844, 0.844],\n",
    "    mode='lines',\n",
    "        name='Normal year scenario <br> (BRSDM model)',\n",
    "    hoverinfo='wet',\n",
    "    showlegend=False,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        dash = 'dashdot',\n",
    "        width='4',\n",
    "        color = '#264DFF'\n",
    "            )\n",
    "                    )\n",
    "data.append(normalHo)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# vertical line wet year \n",
    "wet = go.Scatter(\n",
    "    x=[17181, 17181],\n",
    "    y=[0, 0.93],\n",
    "    mode='lines',\n",
    "        name='Wet year scenario <br> (BRSDM model)',\n",
    "    hoverinfo='wet',\n",
    "    showlegend=True,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        dash = 'dash',\n",
    "        width='4',\n",
    "        color = '#290AD8'\n",
    "            )\n",
    "                    )\n",
    "data.append(wet)\n",
    "\n",
    "\n",
    "# horizontal line wet year \n",
    "wetHo = go.Scatter(\n",
    "    x=[0, 17181],\n",
    "    y=[0.93, 0.93],\n",
    "    mode='lines',\n",
    "        name='Wet year scenario <br> (BRSDM model)',\n",
    "    hoverinfo='wet',\n",
    "    showlegend=False,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        dash = 'dash',\n",
    "        width='4',\n",
    "        color = '#290AD8'\n",
    "            )\n",
    "                    )\n",
    "data.append(wetHo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(\n",
    "        title = \"Cumulative flow for June <br> (acre-feet/month)\",\n",
    "        zeroline=True,\n",
    "         #showline=True,\n",
    "        tickformat= ',',\n",
    "        dtick='10000',\n",
    "        ticks='inside',\n",
    "        ticklen=25,   \n",
    "        range = ['0', '40000'],\n",
    "\n",
    "\n",
    "            ),\n",
    "    yaxis = dict(\n",
    "                title = 'Cumulative probability',\n",
    "                dtick='0.1',\n",
    "                ticks='outside',\n",
    "                ticklen=25,\n",
    "#                 range = ['0', '1'],\n",
    "\n",
    "\n",
    "             showline=True,\n",
    "),\n",
    "    font=dict(size=35,family='arial'),\n",
    "    width=1100,\n",
    "    height=800,\n",
    "    margin=go.Margin(\n",
    "        l=230,\n",
    "        b=150       ),\n",
    "    legend=dict(\n",
    "        x=0.5,y=0.5,\n",
    "            bordercolor='#00000',\n",
    "            borderwidth=2, \n",
    "     font=dict(\n",
    "            family='arial',\n",
    "            size=35                    )           \n",
    "    ),\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "    )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "offline.iplot(fig,filename = 'jupyter/2.4_plotcdf' )       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "### 4. Creating a new HydroShare resource\n",
    "\n",
    "The best way to save your data is to put it back into HydroShare and is done using the `createHydroShareResource` function. The first step is to identify the files you want to save to a HydroShare.  The cell below lists all the files in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define HydroShare required metadata\n",
    "title = 'WaMDaM_Use_Case2.1'\n",
    "abstract = 'This a test for runing a use case of wamdam using jupyter in HydroShare'\n",
    "keywords = ['Time series', 'Bear River']\n",
    "\n",
    "# set the resource type that will be created.\n",
    "rtype = 'genericresource'\n",
    "\n",
    "# create a list of files that will be added to the HydroShare resource.\n",
    "    \n",
    "files = [hs.content['BearRiverDatasets_Jan2018.sqlite'],'WaMDaM_Use_Case2.1.ipynb']  # this notebook\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a hydroshare resource containing these data\n",
    "resource_id = hs.createHydroShareResource(abstract, \n",
    "                                          title, \n",
    "                                          keywords=keywords, \n",
    "                                          resource_type=rtype, \n",
    "                                          content_files=files, \n",
    "                                          public=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Additional Info and citation\n",
    "\n",
    "For additional information on WaMDaM, please refer to:\n",
    "\n",
    "http://docs.wamdam.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
